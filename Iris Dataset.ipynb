{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.plotting import figure,show,output_notebook\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "#import modules, numpy, pandas, bokeh, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the Iris dataset from SKlearn\n",
    "sk_iris = datasets.load_iris()\n",
    "iris = pd.DataFrame(sk_iris.data,columns=sk_iris['feature_names'])\n",
    "iris['target'] = sk_iris.target\n",
    "Names = sk_iris.target_names\n",
    "iris.head()\n",
    "\n",
    "#Iris targets are species names. 3 different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the iris dataset\n",
    "\n",
    "#Create a plot with custom colors\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# plot petal length vs petal width: color by species(target)\n",
    "iris.plot(kind='scatter', x='petal length (cm)', y='petal width (cm)', c='target', colormap=cmap_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot Sepal length vs sepal width: color by species\n",
    "iris.plot(kind='scatter', x='sepal length (cm)', y='sepal width (cm)', c='target', colormap=cmap_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data in to train/test.\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the KNN on the training data. Use 5 neighbors. Then score on the test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "myknn = KNeighborsClassifier(n_neighbors=5)\n",
    "myknn.fit(X_train,y_train)\n",
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN Classifier Model. Lets see how our model will look as we increase # of neighbors\n",
    "# Create a list of the various numbers of neighbors to use to build models\n",
    "# Create training and test sets\n",
    "# Iterate through that list and for each number of neighbors:\n",
    "#    Build a KNN model\n",
    "#    Evaluate it\n",
    "#    Record the score with the number of neighbors for that model\n",
    "# Plot results\n",
    "\n",
    "n_neighbors = range(1, 51)\n",
    "\n",
    "scores = []\n",
    "for n in n_neighbors:\n",
    "    clf = KNeighborsClassifier(n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "knn_scores_df = pd.DataFrame(scores, columns=[\"Accuracy\"])\n",
    "ax = knn_scores_df.plot(figsize=(10,8), title=\"N-Neighbor Parameter Accuracy\")\n",
    "ax.set_xlabel(\"N-Neighbors\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets take a closer look at metrics. Use sklearn.metrics.classification_report to generate a more informative picture\n",
    "# precision = number of items selected that are relevant: True positives/ (true positives + true negatives)\n",
    "# recall = number or relative items selected: true positives/(true positives + false negatives)\n",
    "# Fscore is the harmonic mean of precision and recall: 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([sk_iris['target_names'][label] for label in y_test], \n",
    "                                    [sk_iris['target_names'][label] for label in myknn.predict(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Logistic Regression uses 2 classes.\n",
    "irislog = iris[iris.target!=0]\n",
    "features = irislog.drop('target',axis=1)\n",
    "target = irislog.target\n",
    "\n",
    "#Lets run the LR model and split the data 5 times using cross validation\n",
    "model_lr = LogisticRegression(C=1)\n",
    "cross_val_score(model_lr,features,target,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Determine feature importance\n",
    "model_lr = LogisticRegression(C=1).fit(features, target)\n",
    "x = np.arange(len(features.columns))\n",
    "names = features.columns\n",
    "print names\n",
    "print model_lr.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graph the Coefficient importants\n",
    "p = figure(title=\"Model Coefficients\")\n",
    "for val in x:\n",
    "    p.quad(top=model_lr.coef_.ravel()[val], \n",
    "           bottom=0, left=val+0.2,right=val+0.8, \n",
    "           color=['red','orange','green','purple'][val],\n",
    "           legend=names[val]\n",
    "          )\n",
    "    \n",
    "p.y_range = Range1d(min(model_lr.coef_.ravel())-0.1, max(model_lr.coef_.ravel())+1.5)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The above analysis for Logistic Regression did not normalize data. Lets normalize and our scores should improve.\n",
    "\n",
    "n_features = StandardScaler().fit_transform(features)\n",
    "new_model_lr = LogisticRegression(C=1).fit(n_features, target)\n",
    "print cross_val_score(new_model_lr,features,target,cv=5).mean()\n",
    "print new_model_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = figure(title=\"Model Coefficients Normalized\")\n",
    "for val in x:\n",
    "    p.quad(top=new_model_lr.coef_.ravel()[val], \n",
    "           bottom=0, left=val+0.2,right=val+0.8, \n",
    "           color=['red','orange','green','purple'][val],\n",
    "           legend=names[val]\n",
    "          )\n",
    "    \n",
    "p.y_range = Range1d(min(new_model_lr.coef_.ravel())-0.1, max(new_model_lr.coef_.ravel())+1.5)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run the unsupervised model K-means on Iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#fit the data to 3 different clusters as there are 3 different species\n",
    "km = KMeans(3)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = km.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets compare silihouette scores of clusters as we increase clusters;\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "my_ks = range(2,16)\n",
    "my_ks\n",
    "silhouette = []\n",
    "for k in my_ks:\n",
    "    temp_km = KMeans(k)\n",
    "    temp_km.fit(X)\n",
    "    temp_labels = temp_km.labels_\n",
    "    new_score = silhouette_score(X,temp_labels,metric='euclidean')\n",
    "    silhouette.append(new_score)\n",
    "    \n",
    "p = figure(title='Silhouette')\n",
    "p.line(my_ks,silhouette)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
